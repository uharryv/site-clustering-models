{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running step by step of clustering with commute distance (1st)  site count (2nd) and then headcount (3rd) constraints\n",
    "#### initial cluster are created with proximity, we do NOT allow min and max site count to break it\n",
    "\n",
    "#### Outliers are currently clustered into -1, and then NO further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (make changes here)\n",
    "#DEFAULT_COMMUTE_RADIUS = 180  # miles (approx. 3-hour commute)\n",
    "#DEFAULT_COMMUTE_RADIUS = 360\n",
    "#DEFAULT_COMMUTE_RADIUS = 60 ## primary constraint\n",
    "DEFAULT_COMMUTE_RADIUS= 300\n",
    "\n",
    "MIN_SITES = 6\n",
    "MAX_SITES = 10      ## secondary constraint\n",
    "\n",
    "### headcount constraints (not enforced)\n",
    "hc_min = 8000      ## to be used with 180 miles\n",
    "#hc_min = 15000      ## to be used with 360 miles\n",
    "hc_max = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_locations(file_path):\n",
    "    \"\"\"Load location data from Excel file\"\"\"\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def calculate_distance_miles(coord1, coord2):\n",
    "    \"\"\"Calculate distance between two coordinates in miles\"\"\"\n",
    "    return geodesic(coord1, coord2).miles\n",
    "\n",
    "def safe_join(series):\n",
    "    \"\"\"Join series values handling different data types and null values\"\"\"\n",
    "    if series is None or len(series) == 0:\n",
    "        return \"\"\n",
    "    return ', '.join(str(x) for x in pd.Series(series).dropna().unique() if str(x).strip() != '')\n",
    "\n",
    "\n",
    "# Campus Size Category based on quartiles of OPS_H sum\n",
    "def get_size_category(ops_h_sum, q1, q2, q3):\n",
    "    \"\"\"Classify campus size based on OPS_H sum quartiles\"\"\"\n",
    "    if ops_h_sum < q1:\n",
    "        return \"Small\"\n",
    "    elif ops_h_sum < q2:\n",
    "        return \"Medium\"\n",
    "    elif ops_h_sum < q3:\n",
    "        return \"Large\"\n",
    "    else:\n",
    "        return \"X-Large\"\n",
    "\n",
    "\n",
    "# HR Staffing Levels (base rules)\n",
    "def get_hr_staffing_levels(size_category):\n",
    "    \"\"\"\n",
    "    Returns recommended HR staffing levels based on size category.\n",
    "    Base staffing:\n",
    "      X-Large: Campus Leader=1, HR_L4=16, HR_L5=6, HR_L6=5, HR_L7=2\n",
    "      Large:   Campus Leader=1, HR_L4=11, HR_L5=5, HR_L6=3, HR_L7=1\n",
    "      Medium:  Campus Leader=1, HR_L4=8,  HR_L5=4, HR_L6=2, HR_L7=0\n",
    "      Small:   Campus Leader=1, HR_L4=5,  HR_L5=3, HR_L6=2, HR_L7=0\n",
    "      Multi-Site: Campus Leader=1, HR_L4=1, HR_L5=1, HR_L6=0, HR_L7=0\n",
    "    \"\"\"\n",
    "    staffing_matrix = {\n",
    "        'Small': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 5,\n",
    "            'HR_L5': 3,\n",
    "            'HR_L6': 2,\n",
    "            'HR_L7': 0\n",
    "        },\n",
    "        'Medium': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 8,\n",
    "            'HR_L5': 4,\n",
    "            'HR_L6': 2,\n",
    "            'HR_L7': 0\n",
    "        },\n",
    "        'Large': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 11,\n",
    "            'HR_L5': 5,\n",
    "            'HR_L6': 3,\n",
    "            'HR_L7': 1\n",
    "        },\n",
    "        'X-Large': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 16,\n",
    "            'HR_L5': 6,\n",
    "            'HR_L6': 5,\n",
    "            'HR_L7': 2\n",
    "        },\n",
    "        'Multi-Site': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 1,\n",
    "            'HR_L5': 1,\n",
    "            'HR_L6': 0,\n",
    "            'HR_L7': 0\n",
    "        }\n",
    "    }\n",
    "    return staffing_matrix.get(size_category, {\n",
    "        'Campus_Leader': 0,\n",
    "        'HR_L4': 0,\n",
    "        'HR_L5': 0,\n",
    "        'HR_L6': 0,\n",
    "        'HR_L7': 0\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Analyze clusters and perform HR/staffing analysis.\n",
    "def analyze_clusters(df):\n",
    "    \"\"\"Generate summary statistics and staffing analysis for each campus.\"\"\"\n",
    "    cluster_stats = []\n",
    "    cluster_ids = df['cluster_id'].unique()\n",
    "    \n",
    "    # Compute quartile thresholds for OPS_H from valid (non-outlier) clusters.\n",
    "    campus_sizes = []\n",
    "    for cid in cluster_ids:\n",
    "        cluster_data = df[df['cluster_id'] == cid]\n",
    "        if not cluster_data['is_outlier'].all():\n",
    "            campus_sizes.append(cluster_data['OPS_H'].sum())\n",
    "    if campus_sizes:\n",
    "        q1_size = np.percentile(campus_sizes, 25)\n",
    "        q2_size = np.percentile(campus_sizes, 50)\n",
    "        q3_size = np.percentile(campus_sizes, 75)\n",
    "    else:\n",
    "        q1_size, q2_size, q3_size = 15000, 30000, 50000\n",
    "\n",
    "    for cid in cluster_ids:\n",
    "        cluster_data = df[df['cluster_id'] == cid]\n",
    "        center_lat = cluster_data['latitude'].mean()\n",
    "        center_lon = cluster_data['longitude'].mean()\n",
    "        \n",
    "        max_distance = 0\n",
    "        sites = cluster_data[['latitude', 'longitude']].values\n",
    "        if len(sites) > 1:\n",
    "            for i in range(len(sites)):\n",
    "                for j in range(i+1, len(sites)):\n",
    "                    d = calculate_distance_miles(sites[i], sites[j])\n",
    "                    if d > max_distance:\n",
    "                        max_distance = d\n",
    "        \n",
    "        cluster_aa_hc = cluster_data['OPS_H'].sum()\n",
    "        cluster_ops_hc = cluster_data['OPS_S'].sum()\n",
    "        \n",
    "        # Current staffing summary (if such columns exist)\n",
    "        current_staffing = {\n",
    "            'Current_Campus_Leader': 1 if 'Campus_Leader' in cluster_data.columns else 0,\n",
    "            'Current_HR_L4': cluster_data['HR_4'].sum() if 'HR_4' in cluster_data.columns else 0,\n",
    "            'Current_HR_L5': cluster_data['HR_5'].sum() if 'HR_5' in cluster_data.columns else 0,\n",
    "            'Current_HR_L6': cluster_data['HR_6'].sum() if 'HR_6' in cluster_data.columns else 0,\n",
    "            'Current_HR_L7': cluster_data['HR_7'].sum() if 'HR_7' in cluster_data.columns else 0\n",
    "        }\n",
    "        current_hr_total = sum(current_staffing.values())\n",
    "        current_gearing_ratio = (cluster_aa_hc / current_hr_total) if current_hr_total else None\n",
    "        current_gearing_ratio_ops = (cluster_ops_hc / current_hr_total) if current_hr_total else None\n",
    "        \n",
    "        if cluster_data['multi_site'].any():\n",
    "            size_category = \"Multi-Site\"\n",
    "            new_hr_staffing = get_hr_staffing_levels(\"Multi-Site\")\n",
    "        else:\n",
    "            size_category = get_size_category(cluster_aa_hc, q1_size, q2_size, q3_size)\n",
    "            new_hr_staffing = get_hr_staffing_levels(size_category)\n",
    "        \n",
    "        new_hr_total = sum(new_hr_staffing.values())\n",
    "        new_gearing_ratio = (cluster_aa_hc / new_hr_total) if new_hr_total else None\n",
    "        new_gearing_ratio_ops = (cluster_ops_hc / new_hr_total) if new_hr_total else None\n",
    "        \n",
    "        stats = {\n",
    "            'cluster_id': cid,\n",
    "            'num_sites': len(cluster_data),\n",
    "            'size_category': size_category,\n",
    "            'Cluster_AA_HC': cluster_aa_hc,\n",
    "            'Cluster_OPS_HC': cluster_ops_hc,\n",
    "            'Current_Campus_Leader': current_staffing['Current_Campus_Leader'],\n",
    "            'Current_HR_L4': current_staffing['Current_HR_L4'],\n",
    "            'Current_HR_L5': current_staffing['Current_HR_L5'],\n",
    "            'Current_HR_L6': current_staffing['Current_HR_L6'],\n",
    "            'Current_HR_L7': current_staffing['Current_HR_L7'],\n",
    "            'Current_HR_Total': current_hr_total,\n",
    "            'Current_Gearing_Ratio_AA': current_gearing_ratio,\n",
    "            'Current_Gearing_Ratio_OPS': current_gearing_ratio_ops,\n",
    "            'New_Campus_Leader': new_hr_staffing['Campus_Leader'],\n",
    "            'New_HR_L4': new_hr_staffing['HR_L4'],\n",
    "            'New_HR_L5': new_hr_staffing['HR_L5'],\n",
    "            'New_HR_L6': new_hr_staffing['HR_L6'],\n",
    "            'New_HR_L7': new_hr_staffing['HR_L7'],\n",
    "            'New_HR_Total': new_hr_total,\n",
    "            'New_Gearing_Ratio_AA': new_gearing_ratio,\n",
    "            'New_Gearing_Ratio_OPS': new_gearing_ratio_ops,\n",
    "            'country': safe_join(cluster_data['country']),\n",
    "            'markets': safe_join(cluster_data['market']),\n",
    "            'cities': safe_join(cluster_data['city']),\n",
    "            'states': safe_join(cluster_data['state']),\n",
    "            'center_latitude': center_lat,\n",
    "            'center_longitude': center_lon,\n",
    "            'max_distance_miles': round(max_distance, 2),\n",
    "            'num_reassigned_outliers': len(cluster_data[cluster_data['reassignment_type'].notnull()])\n",
    "        }\n",
    "        cluster_stats.append(stats)\n",
    "    \n",
    "    df_stats = pd.DataFrame(cluster_stats)\n",
    "    # Round gearing ratios for presentation.\n",
    "    for col in ['Current_Gearing_Ratio_AA', 'Current_Gearing_Ratio_OPS',\n",
    "                'New_Gearing_Ratio_AA', 'New_Gearing_Ratio_OPS']:\n",
    "        df_stats[col] = df_stats[col].apply(lambda x: round(x, 2) if pd.notnull(x) else x)\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1118, 17)\n"
     ]
    }
   ],
   "source": [
    "### load file\n",
    "df = pd.read_excel('../data_files/input/locations.xlsx')\n",
    "print(df.shape)\n",
    "\n",
    "## distance matrix b/w site locations\n",
    "\n",
    "coords = df[['latitude', 'longitude']].values\n",
    "dist_matrix = squareform(pdist(coords, metric=lambda u, v: calculate_distance_miles(u, v)))\n",
    "\n",
    "print(dist_matrix.min(),dist_matrix.max(),dist_matrix.mean())\n",
    "print(np.quantile(dist_matrix, 0.25), np.quantile(dist_matrix, 0.5), np.quantile(dist_matrix, 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "### clustering 1st pass\n",
    "\n",
    "df_clustered = df.copy()\n",
    "\n",
    "#commute_radius = DEFAULT_COMMUTE_RADIUS/5    ## for 60\n",
    "#commute_radius = DEFAULT_COMMUTE_RADIUS/4    ## for 180\n",
    "#commute_radius = DEFAULT_COMMUTE_RADIUS/5     ## for 360\n",
    "commute_radius = DEFAULT_COMMUTE_RADIUS/6     ## for 300\n",
    "\n",
    "min_sites = MIN_SITES\n",
    "max_sites = MAX_SITES\n",
    "\n",
    "##### stats for 60 miles\n",
    "### DEFAULT_COMMUTE_RADIUS/4 is when we get 3 cluster with max distance > commute radius; but outlier is 40% of sites\n",
    "### DEFAULT_COMMUTE_RADIUS/5 is when we get 0 cluster with max distance > commute radius; but outliers is 51% of sites \n",
    "\n",
    "clustering = DBSCAN(eps=commute_radius, min_samples=min_sites, metric='precomputed')\n",
    "cluster_labels = clustering.fit_predict(dist_matrix)\n",
    "df_clustered['cluster_id'] = cluster_labels\n",
    "df_clustered['initial_outlier'] = (cluster_labels == -1)\n",
    "df_clustered['outlier_reassigned'] = False\n",
    "df_clustered['is_outlier'] = (cluster_labels == -1)\n",
    "df_clustered['multi_site'] = False\n",
    "df_clustered['reassignment_type'] = None\n",
    "\n",
    "print(df_clustered['cluster_id'].nunique())\n",
    "\n",
    "### Analyse initial cluster\n",
    "cluster_analysis = analyze_clusters(df_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "0.19230769230769232\n"
     ]
    }
   ],
   "source": [
    "### #outliers grouped into -1 cluster\n",
    "\n",
    "print(cluster_analysis[(cluster_analysis['cluster_id'] == -1)]['num_sites'].sum())\n",
    "print(cluster_analysis[(cluster_analysis['cluster_id'] == -1)]['num_sites'].sum() / cluster_analysis['num_sites'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.02857142857142857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.800000</td>\n",
       "      <td>19605.371429</td>\n",
       "      <td>87.338571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.896393</td>\n",
       "      <td>27566.381577</td>\n",
       "      <td>89.108605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3602.000000</td>\n",
       "      <td>14.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>7263.500000</td>\n",
       "      <td>37.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>12969.000000</td>\n",
       "      <td>65.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.500000</td>\n",
       "      <td>20636.500000</td>\n",
       "      <td>107.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>231.000000</td>\n",
       "      <td>160341.000000</td>\n",
       "      <td>525.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count   35.000000      35.000000           35.000000\n",
       "mean    25.800000   19605.371429           87.338571\n",
       "std     38.896393   27566.381577           89.108605\n",
       "min      6.000000    3602.000000           14.260000\n",
       "25%     11.000000    7263.500000           37.325000\n",
       "50%     15.000000   12969.000000           65.820000\n",
       "75%     23.500000   20636.500000          107.980000\n",
       "max    231.000000  160341.000000          525.030000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_analysis_no_outlier = cluster_analysis[~(cluster_analysis['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have max distance > DEFAULT_COMMUTE_RADIUS\n",
    "print(len(cluster_analysis_no_outlier[cluster_analysis_no_outlier['max_distance_miles'] > DEFAULT_COMMUTE_RADIUS]))\n",
    "print(len(cluster_analysis_no_outlier[cluster_analysis_no_outlier['max_distance_miles'] > DEFAULT_COMMUTE_RADIUS])/ len(cluster_analysis_no_outlier))\n",
    "\n",
    "cluster_analysis_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_sites</th>\n",
       "      <th>size_category</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>Cluster_OPS_HC</th>\n",
       "      <th>Current_Campus_Leader</th>\n",
       "      <th>Current_HR_L4</th>\n",
       "      <th>Current_HR_L5</th>\n",
       "      <th>Current_HR_L6</th>\n",
       "      <th>Current_HR_L7</th>\n",
       "      <th>...</th>\n",
       "      <th>New_Gearing_Ratio_AA</th>\n",
       "      <th>New_Gearing_Ratio_OPS</th>\n",
       "      <th>country</th>\n",
       "      <th>markets</th>\n",
       "      <th>cities</th>\n",
       "      <th>states</th>\n",
       "      <th>center_latitude</th>\n",
       "      <th>center_longitude</th>\n",
       "      <th>max_distance_miles</th>\n",
       "      <th>num_reassigned_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>231</td>\n",
       "      <td>X-Large</td>\n",
       "      <td>160341</td>\n",
       "      <td>6369</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>203</td>\n",
       "      <td>113</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>5344.7</td>\n",
       "      <td>212.3</td>\n",
       "      <td>United States</td>\n",
       "      <td>Virginia Beach-Norfolk-Newport News, VA-NC, Wa...</td>\n",
       "      <td>Virginia Beach, Forestville, West Deptford, Wi...</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.264041</td>\n",
       "      <td>-74.875234</td>\n",
       "      <td>525.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id  num_sites size_category  Cluster_AA_HC  Cluster_OPS_HC  \\\n",
       "5           5        231       X-Large         160341            6369   \n",
       "\n",
       "   Current_Campus_Leader  Current_HR_L4  Current_HR_L5  Current_HR_L6  \\\n",
       "5                      0            222            203            113   \n",
       "\n",
       "   Current_HR_L7  ...  New_Gearing_Ratio_AA  New_Gearing_Ratio_OPS  \\\n",
       "5             37  ...                5344.7                  212.3   \n",
       "\n",
       "         country                                            markets  \\\n",
       "5  United States  Virginia Beach-Norfolk-Newport News, VA-NC, Wa...   \n",
       "\n",
       "                                              cities         states  \\\n",
       "5  Virginia Beach, Forestville, West Deptford, Wi...  United States   \n",
       "\n",
       "   center_latitude  center_longitude  max_distance_miles  \\\n",
       "5        40.264041        -74.875234              525.03   \n",
       "\n",
       "   num_reassigned_outliers  \n",
       "5                        0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### what are the clusters with max distance above DEFAULT_COMMUTE_RADIUS\n",
    "cluster_analysis_no_outlier[cluster_analysis_no_outlier['max_distance_miles'] > DEFAULT_COMMUTE_RADIUS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now adding site_count as secondary constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "df_adjusted = df_clustered.copy()\n",
    "\n",
    "# Split clusters that are too large (by site count)\n",
    "clusters = df_adjusted[df_adjusted['cluster_id'] != -1]['cluster_id'].unique()\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted[df_adjusted['cluster_id'] == cid]\n",
    "    if len(cluster_data) > max_sites:\n",
    "        changed = True\n",
    "        n_subclusters = int(np.ceil(len(cluster_data) / max_sites))\n",
    "        coords = cluster_data[['latitude', 'longitude']].values\n",
    "        kmeans = KMeans(n_clusters=n_subclusters, random_state=42)\n",
    "        sub_labels = kmeans.fit_predict(coords)\n",
    "        new_cluster_id = df_adjusted['cluster_id'].max() + 1\n",
    "        for sub in np.unique(sub_labels):\n",
    "            indices = cluster_data.index[sub_labels == sub]\n",
    "            df_adjusted.loc[indices, 'cluster_id'] = new_cluster_id\n",
    "            new_cluster_id += 1\n",
    "\n",
    "print(df_adjusted['cluster_id'].nunique())\n",
    "\n",
    "### Analyse adjusted clusters new constraint\n",
    "cluster_adj_analysis = analyze_clusters(df_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0.2962962962962963\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>108.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.361111</td>\n",
       "      <td>6353.592593</td>\n",
       "      <td>34.837130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.508472</td>\n",
       "      <td>4265.292448</td>\n",
       "      <td>20.908976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3572.750000</td>\n",
       "      <td>20.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5210.500000</td>\n",
       "      <td>30.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>9244.500000</td>\n",
       "      <td>47.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25570.000000</td>\n",
       "      <td>118.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count  108.000000     108.000000          108.000000\n",
       "mean     8.361111    6353.592593           34.837130\n",
       "std      4.508472    4265.292448           20.908976\n",
       "min      1.000000     120.000000            0.000000\n",
       "25%      5.000000    3572.750000           20.917500\n",
       "50%      7.000000    5210.500000           30.440000\n",
       "75%     11.000000    9244.500000           47.887500\n",
       "max     25.000000   25570.000000          118.100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_adj_analysis_no_outlier = cluster_adj_analysis[~(cluster_adj_analysis['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have num_sites > MAX_SITES\n",
    "print(len(cluster_adj_analysis_no_outlier[cluster_adj_analysis_no_outlier['num_sites'] > MAX_SITES]))\n",
    "print(len(cluster_adj_analysis_no_outlier[cluster_adj_analysis_no_outlier['num_sites'] > MAX_SITES])/ len(cluster_adj_analysis_no_outlier))\n",
    "\n",
    "cluster_adj_analysis_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()\n",
    "\n",
    "\n",
    "### 32 cluster has > max site count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "### repeating once more !!!\n",
    "\n",
    "df_adjusted_2 = df_adjusted.copy()\n",
    "\n",
    "# Split clusters that are too large (by site count)\n",
    "clusters = df_adjusted_2[df_adjusted_2['cluster_id'] != -1]['cluster_id'].unique()\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted_2[df_adjusted_2['cluster_id'] == cid]\n",
    "    if len(cluster_data) > max_sites:\n",
    "        changed = True\n",
    "        n_subclusters = int(np.ceil(len(cluster_data) / max_sites))\n",
    "        coords = cluster_data[['latitude', 'longitude']].values\n",
    "        kmeans = KMeans(n_clusters=n_subclusters, random_state=42)\n",
    "        sub_labels = kmeans.fit_predict(coords)\n",
    "        new_cluster_id = df_adjusted_2['cluster_id'].max() + 1\n",
    "        for sub in np.unique(sub_labels):\n",
    "            indices = cluster_data.index[sub_labels == sub]\n",
    "            df_adjusted_2.loc[indices, 'cluster_id'] = new_cluster_id\n",
    "            new_cluster_id += 1\n",
    "\n",
    "print(df_adjusted_2['cluster_id'].nunique())\n",
    "\n",
    "### Analyse adjusted clusters after ops headcount constraint\n",
    "cluster_adj_analysis_2 = analyze_clusters(df_adjusted_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0.04929577464788732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.359155</td>\n",
       "      <td>4832.309859</td>\n",
       "      <td>25.055563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.090460</td>\n",
       "      <td>3390.568883</td>\n",
       "      <td>18.608298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2222.250000</td>\n",
       "      <td>13.492500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>4092.000000</td>\n",
       "      <td>22.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>6908.250000</td>\n",
       "      <td>32.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>15010.000000</td>\n",
       "      <td>78.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count  142.000000     142.000000          142.000000\n",
       "mean     6.359155    4832.309859           25.055563\n",
       "std      3.090460    3390.568883           18.608298\n",
       "min      1.000000     120.000000            0.000000\n",
       "25%      4.000000    2222.250000           13.492500\n",
       "50%      6.500000    4092.000000           22.130000\n",
       "75%      8.000000    6908.250000           32.915000\n",
       "max     19.000000   15010.000000           78.250000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_adj_analysis_2_no_outlier = cluster_adj_analysis_2[~(cluster_adj_analysis_2['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have num sites > max sites\n",
    "print(len(cluster_adj_analysis_2_no_outlier[cluster_adj_analysis_2_no_outlier['num_sites'] > MAX_SITES]))\n",
    "print(len(cluster_adj_analysis_2_no_outlier[cluster_adj_analysis_2_no_outlier['num_sites'] > MAX_SITES])/ len(cluster_adj_analysis_2_no_outlier))\n",
    "\n",
    "cluster_adj_analysis_2_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()\n",
    "\n",
    "\n",
    "### 7 CLUSTERS has > max sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "### repeating once more !!!\n",
    "\n",
    "df_adjusted_3 = df_adjusted_2.copy()\n",
    "\n",
    "# Split clusters that are too large (by site count)\n",
    "clusters = df_adjusted_3[df_adjusted_3['cluster_id'] != -1]['cluster_id'].unique()\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted_3[df_adjusted_3['cluster_id'] == cid]\n",
    "    if len(cluster_data) > max_sites:\n",
    "        changed = True\n",
    "        n_subclusters = int(np.ceil(len(cluster_data) / max_sites))\n",
    "        coords = cluster_data[['latitude', 'longitude']].values\n",
    "        kmeans = KMeans(n_clusters=n_subclusters, random_state=42)\n",
    "        sub_labels = kmeans.fit_predict(coords)\n",
    "        new_cluster_id = df_adjusted_3['cluster_id'].max() + 1\n",
    "        for sub in np.unique(sub_labels):\n",
    "            indices = cluster_data.index[sub_labels == sub]\n",
    "            df_adjusted_3.loc[indices, 'cluster_id'] = new_cluster_id\n",
    "            new_cluster_id += 1\n",
    "\n",
    "print(df_adjusted_3['cluster_id'].nunique())\n",
    "\n",
    "### Analyse adjusted clusters after ops headcount constraint\n",
    "cluster_adj_analysis_3 = analyze_clusters(df_adjusted_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.006711409395973154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.060403</td>\n",
       "      <td>4605.288591</td>\n",
       "      <td>23.998255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.602567</td>\n",
       "      <td>3221.915467</td>\n",
       "      <td>18.052673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>11.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>20.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>6818.000000</td>\n",
       "      <td>32.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>15010.000000</td>\n",
       "      <td>74.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count  149.000000     149.000000          149.000000\n",
       "mean     6.060403    4605.288591           23.998255\n",
       "std      2.602567    3221.915467           18.052673\n",
       "min      1.000000     120.000000            0.000000\n",
       "25%      4.000000    1960.000000           11.620000\n",
       "50%      6.000000    3999.000000           20.440000\n",
       "75%      8.000000    6818.000000           32.130000\n",
       "max     11.000000   15010.000000           74.770000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_adj_analysis_3_no_outlier = cluster_adj_analysis_3[~(cluster_adj_analysis_3['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have num sites > max sites\n",
    "print(len(cluster_adj_analysis_3_no_outlier[cluster_adj_analysis_3_no_outlier['num_sites'] > MAX_SITES]))\n",
    "print(len(cluster_adj_analysis_3_no_outlier[cluster_adj_analysis_3_no_outlier['num_sites'] > MAX_SITES])/ len(cluster_adj_analysis_3_no_outlier))\n",
    "\n",
    "cluster_adj_analysis_3_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()\n",
    "\n",
    "\n",
    "### 1 CLUSTERS has > max sites\n",
    "##thats ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### further grouping sites below min site count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "### for 60 miles\n",
    "#print(len(cluster_adj_analysis_2_no_outlier[cluster_adj_analysis_2_no_outlier['num_sites'] < MIN_SITES]))\n",
    "\n",
    "### for 300 miles\n",
    "print(len(cluster_adj_analysis_3_no_outlier[cluster_adj_analysis_3_no_outlier['num_sites'] < MIN_SITES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "df_adjusted_4= df_adjusted_3.copy()\n",
    "\n",
    "# Merge clusters that are too small (by site count)\n",
    "\n",
    "clusters = df_adjusted_4[df_adjusted_4['cluster_id'] != -1]['cluster_id'].unique()\n",
    "cluster_centers = {cid: (df_adjusted_4[df_adjusted_4['cluster_id'] == cid]['latitude'].mean(),\n",
    "                         df_adjusted_4[df_adjusted_4['cluster_id'] == cid]['longitude'].mean())\n",
    "                    for cid in clusters}\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted_4[df_adjusted_4['cluster_id'] == cid]\n",
    "    #aa_hc = cluster_data['OPS_H'].sum()\n",
    "    if len(cluster_data) < min_sites:\n",
    "        candidate = None\n",
    "        min_dist = float('inf')\n",
    "        for other_cid in clusters:\n",
    "            if other_cid == cid:\n",
    "                continue\n",
    "            other_data = df_adjusted_4[df_adjusted_4['cluster_id'] == other_cid]\n",
    "            combined_sites = len(cluster_data) + len(other_data)\n",
    "            #combined_aa_hc = aa_hc + other_data['OPS_H'].sum()\n",
    "            if combined_sites <= max_sites:\n",
    "                d = calculate_distance_miles(cluster_centers[cid], cluster_centers[other_cid])\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    candidate = other_cid\n",
    "        if candidate is not None:\n",
    "            df_adjusted_4.loc[df_adjusted_4['cluster_id'] == cid, 'cluster_id'] = candidate\n",
    "            changed = True\n",
    "\n",
    "\n",
    "print(df_adjusted_4['cluster_id'].nunique())\n",
    "\n",
    "### Analyse adjusted clusters after ops headcount constraint\n",
    "cluster_adj_analysis_4 = analyze_clusters(df_adjusted_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.08547008547008547\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.717949</td>\n",
       "      <td>5864.854701</td>\n",
       "      <td>37.41188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.770672</td>\n",
       "      <td>3166.829983</td>\n",
       "      <td>28.92238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>3.44000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3239.000000</td>\n",
       "      <td>18.49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>5138.000000</td>\n",
       "      <td>27.37000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>8175.000000</td>\n",
       "      <td>52.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>15010.000000</td>\n",
       "      <td>192.15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count  117.000000     117.000000           117.00000\n",
       "mean     7.717949    5864.854701            37.41188\n",
       "std      1.770672    3166.829983            28.92238\n",
       "min      2.000000     598.000000             3.44000\n",
       "25%      7.000000    3239.000000            18.49000\n",
       "50%      8.000000    5138.000000            27.37000\n",
       "75%      9.000000    8175.000000            52.01000\n",
       "max     11.000000   15010.000000           192.15000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_adj_analysis_4_no_outlier = cluster_adj_analysis_4[~(cluster_adj_analysis_4['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have num sites < min sites\n",
    "print(len(cluster_adj_analysis_4_no_outlier[cluster_adj_analysis_4_no_outlier['num_sites'] < MIN_SITES]))\n",
    "print(len(cluster_adj_analysis_4_no_outlier[cluster_adj_analysis_4_no_outlier['num_sites'] < MIN_SITES])/ len(cluster_adj_analysis_4_no_outlier))\n",
    "\n",
    "cluster_adj_analysis_4_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()\n",
    "\n",
    "\n",
    "### 10 CLUSTERS has < min sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "### repeating once more !!!\n",
    "\n",
    "df_adjusted_5= df_adjusted_4.copy()\n",
    "\n",
    "# Merge clusters that are too small (by site count)\n",
    "\n",
    "clusters = df_adjusted_5[df_adjusted_5['cluster_id'] != -1]['cluster_id'].unique()\n",
    "cluster_centers = {cid: (df_adjusted_5[df_adjusted_5['cluster_id'] == cid]['latitude'].mean(),\n",
    "                         df_adjusted_5[df_adjusted_5['cluster_id'] == cid]['longitude'].mean())\n",
    "                    for cid in clusters}\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted_5[df_adjusted_5['cluster_id'] == cid]\n",
    "    #aa_hc = cluster_data['OPS_H'].sum()\n",
    "    if len(cluster_data) < min_sites:\n",
    "        candidate = None\n",
    "        min_dist = float('inf')\n",
    "        for other_cid in clusters:\n",
    "            if other_cid == cid:\n",
    "                continue\n",
    "            other_data = df_adjusted_5[df_adjusted_5['cluster_id'] == other_cid]\n",
    "            combined_sites = len(cluster_data) + len(other_data)\n",
    "            #combined_aa_hc = aa_hc + other_data['OPS_H'].sum()\n",
    "            if combined_sites <= max_sites:\n",
    "                d = calculate_distance_miles(cluster_centers[cid], cluster_centers[other_cid])\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    candidate = other_cid\n",
    "        if candidate is not None:\n",
    "            df_adjusted_5.loc[df_adjusted_5['cluster_id'] == cid, 'cluster_id'] = candidate\n",
    "            changed = True\n",
    "\n",
    "\n",
    "print(df_adjusted_5['cluster_id'].nunique())\n",
    "\n",
    "### Analyse adjusted clusters after ops headcount constraint\n",
    "cluster_adj_analysis_5 = analyze_clusters(df_adjusted_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>111.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.135135</td>\n",
       "      <td>6181.873874</td>\n",
       "      <td>51.603423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.344933</td>\n",
       "      <td>3012.627857</td>\n",
       "      <td>67.571120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>3.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3670.000000</td>\n",
       "      <td>18.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>5548.000000</td>\n",
       "      <td>31.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>8284.500000</td>\n",
       "      <td>58.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>15010.000000</td>\n",
       "      <td>421.330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count  111.000000     111.000000          111.000000\n",
       "mean     8.135135    6181.873874           51.603423\n",
       "std      1.344933    3012.627857           67.571120\n",
       "min      6.000000    1730.000000            3.440000\n",
       "25%      7.000000    3670.000000           18.645000\n",
       "50%      8.000000    5548.000000           31.170000\n",
       "75%      9.000000    8284.500000           58.825000\n",
       "max     11.000000   15010.000000          421.330000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_adj_analysis_5_no_outlier = cluster_adj_analysis_5[~(cluster_adj_analysis_5['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have num sites < min sites\n",
    "print(len(cluster_adj_analysis_5_no_outlier[cluster_adj_analysis_5_no_outlier['num_sites'] < MIN_SITES]))\n",
    "print(len(cluster_adj_analysis_5_no_outlier[cluster_adj_analysis_5_no_outlier['num_sites'] < MIN_SITES])/ len(cluster_adj_analysis_5_no_outlier))\n",
    "\n",
    "cluster_adj_analysis_5_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()\n",
    "\n",
    "\n",
    "### No CLUSTERS has < min sites -> but this break proimity constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>num_sites</th>\n",
       "      <th>size_category</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>Cluster_OPS_HC</th>\n",
       "      <th>Current_Campus_Leader</th>\n",
       "      <th>Current_HR_L4</th>\n",
       "      <th>Current_HR_L5</th>\n",
       "      <th>Current_HR_L6</th>\n",
       "      <th>Current_HR_L7</th>\n",
       "      <th>...</th>\n",
       "      <th>New_Gearing_Ratio_AA</th>\n",
       "      <th>New_Gearing_Ratio_OPS</th>\n",
       "      <th>country</th>\n",
       "      <th>markets</th>\n",
       "      <th>cities</th>\n",
       "      <th>states</th>\n",
       "      <th>center_latitude</th>\n",
       "      <th>center_longitude</th>\n",
       "      <th>max_distance_miles</th>\n",
       "      <th>num_reassigned_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Large</td>\n",
       "      <td>5958</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>283.71</td>\n",
       "      <td>12.52</td>\n",
       "      <td>United States</td>\n",
       "      <td>Boise City, ID, Salt Lake City, UT, Provo-Orem...</td>\n",
       "      <td>Nampa, Boise, West Jordan, Meridian, American ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>42.330750</td>\n",
       "      <td>-114.591921</td>\n",
       "      <td>331.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>Large</td>\n",
       "      <td>6123</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>291.57</td>\n",
       "      <td>10.95</td>\n",
       "      <td>United States</td>\n",
       "      <td>Dayton-Kettering, OH, Wilmington, OH, Staunton...</td>\n",
       "      <td>Vandalia, Kettering, Wilmington, Fishersville,...</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.232713</td>\n",
       "      <td>-82.147496</td>\n",
       "      <td>317.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4079</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>271.93</td>\n",
       "      <td>14.20</td>\n",
       "      <td>United States</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta, GA, Deltona-...</td>\n",
       "      <td>Atlanta, White, Daytona Beach, Deltona, Lithia...</td>\n",
       "      <td>United States</td>\n",
       "      <td>31.775230</td>\n",
       "      <td>-83.304336</td>\n",
       "      <td>421.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>Small</td>\n",
       "      <td>2353</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213.91</td>\n",
       "      <td>15.55</td>\n",
       "      <td>United States</td>\n",
       "      <td>St. Louis, MO-IL, Madison, WI</td>\n",
       "      <td>Edwardsville, Madison, Pontoon Beach, East Sai...</td>\n",
       "      <td>United States</td>\n",
       "      <td>40.661538</td>\n",
       "      <td>-89.739389</td>\n",
       "      <td>314.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cluster_id  num_sites size_category  Cluster_AA_HC  Cluster_OPS_HC  \\\n",
       "22           12         10         Large           5958             263   \n",
       "44           69          8         Large           6123             230   \n",
       "89           36          9        Medium           4079             213   \n",
       "110         178          9         Small           2353             171   \n",
       "\n",
       "     Current_Campus_Leader  Current_HR_L4  Current_HR_L5  Current_HR_L6  \\\n",
       "22                       0              8             11              4   \n",
       "44                       0              6              8              4   \n",
       "89                       0              7              8              3   \n",
       "110                      0              5              6              2   \n",
       "\n",
       "     Current_HR_L7  ...  New_Gearing_Ratio_AA  New_Gearing_Ratio_OPS  \\\n",
       "22               1  ...                283.71                  12.52   \n",
       "44               1  ...                291.57                  10.95   \n",
       "89               3  ...                271.93                  14.20   \n",
       "110              0  ...                213.91                  15.55   \n",
       "\n",
       "           country                                            markets  \\\n",
       "22   United States  Boise City, ID, Salt Lake City, UT, Provo-Orem...   \n",
       "44   United States  Dayton-Kettering, OH, Wilmington, OH, Staunton...   \n",
       "89   United States  Atlanta-Sandy Springs-Alpharetta, GA, Deltona-...   \n",
       "110  United States                      St. Louis, MO-IL, Madison, WI   \n",
       "\n",
       "                                                cities         states  \\\n",
       "22   Nampa, Boise, West Jordan, Meridian, American ...  United States   \n",
       "44   Vandalia, Kettering, Wilmington, Fishersville,...  United States   \n",
       "89   Atlanta, White, Daytona Beach, Deltona, Lithia...  United States   \n",
       "110  Edwardsville, Madison, Pontoon Beach, East Sai...  United States   \n",
       "\n",
       "     center_latitude  center_longitude  max_distance_miles  \\\n",
       "22         42.330750       -114.591921              331.70   \n",
       "44         39.232713        -82.147496              317.41   \n",
       "89         31.775230        -83.304336              421.33   \n",
       "110        40.661538        -89.739389              314.70   \n",
       "\n",
       "     num_reassigned_outliers  \n",
       "22                         0  \n",
       "44                         0  \n",
       "89                         0  \n",
       "110                        0  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### what are the clusters with max distance above DEFAULT_COMMUTE_RADIUS\n",
    "cluster_adj_analysis_5_no_outlier[cluster_adj_analysis_5_no_outlier['max_distance_miles'] > DEFAULT_COMMUTE_RADIUS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT RUN\n",
    "\n",
    "###  try 3rd constraint headcount\n",
    "\n",
    "### no way to apply headcount constraint without breaking both of previous constraints - DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "df_adjusted_4 = df_adjusted_3.copy()\n",
    "\n",
    "# Merge clusters that are too small (by OPS_H sum < hc_min)\n",
    "clusters = df_adjusted_4[df_adjusted_4['cluster_id'] != -1]['cluster_id'].unique()\n",
    "cluster_centers = {cid: (df_adjusted_4[df_adjusted_4['cluster_id'] == cid]['latitude'].mean(),\n",
    "                         df_adjusted_4[df_adjusted_4['cluster_id'] == cid]['longitude'].mean())\n",
    "                  for cid in clusters}\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted_4[df_adjusted_4['cluster_id'] == cid]\n",
    "    aa_hc = cluster_data['OPS_H'].sum()\n",
    "    if aa_hc < (hc_min):\n",
    "        candidate = None\n",
    "        min_dist = float('inf')\n",
    "        for other_cid in clusters:\n",
    "            if other_cid == cid:\n",
    "                continue\n",
    "            other_data = df_adjusted_4[df_adjusted_4['cluster_id'] == other_cid]\n",
    "            combined_sites = len(cluster_data) + len(other_data)\n",
    "            combined_aa_hc = aa_hc + other_data['OPS_H'].sum()\n",
    "            ## to make sure it doesn't break max sites rule\n",
    "            if combined_aa_hc <= hc_max and combined_sites < max_sites:\n",
    "                d = calculate_distance_miles(cluster_centers[cid], cluster_centers[other_cid])\n",
    "                #if d < min_dist and d < (DEFAULT_COMMUTE_RADIUS-5):\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    candidate = other_cid\n",
    "        if candidate is not None:\n",
    "            df_adjusted_4.loc[df_adjusted_4['cluster_id'] == cid, 'cluster_id'] = candidate\n",
    "            changed = True\n",
    "\n",
    "\n",
    "print(df_adjusted_4['cluster_id'].nunique())\n",
    "\n",
    "### Analyse adjusted clusters after ops headcount constraint\n",
    "cluster_adj_analysis_4 = analyze_clusters(df_adjusted_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "0.5294117647058824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites</th>\n",
       "      <th>Cluster_AA_HC</th>\n",
       "      <th>max_distance_miles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.588235</td>\n",
       "      <td>8413.392157</td>\n",
       "      <td>22.668627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.210351</td>\n",
       "      <td>4680.199218</td>\n",
       "      <td>10.437401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2149.000000</td>\n",
       "      <td>4.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>5017.500000</td>\n",
       "      <td>17.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>7627.000000</td>\n",
       "      <td>21.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>10667.500000</td>\n",
       "      <td>26.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>23698.000000</td>\n",
       "      <td>56.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_sites  Cluster_AA_HC  max_distance_miles\n",
       "count  51.000000      51.000000           51.000000\n",
       "mean   10.588235    8413.392157           22.668627\n",
       "std     4.210351    4680.199218           10.437401\n",
       "min     6.000000    2149.000000            4.440000\n",
       "25%     7.000000    5017.500000           17.465000\n",
       "50%    10.000000    7627.000000           21.680000\n",
       "75%    13.000000   10667.500000           26.600000\n",
       "max    20.000000   23698.000000           56.200000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## except outliers, summary of remaining clusters\n",
    "cluster_adj_analysis_4_no_outlier = cluster_adj_analysis_4[~(cluster_adj_analysis_4['cluster_id'] == -1)]\n",
    "\n",
    "##how many clusters have headcount > hc_min\n",
    "print(len(cluster_adj_analysis_4_no_outlier[cluster_adj_analysis_4_no_outlier['Cluster_AA_HC'] < hc_min]))\n",
    "print(len(cluster_adj_analysis_4_no_outlier[cluster_adj_analysis_4_no_outlier['Cluster_AA_HC'] < hc_min])/ len(cluster_adj_analysis_4_no_outlier))\n",
    "\n",
    "cluster_adj_analysis_4_no_outlier[['num_sites','Cluster_AA_HC','max_distance_miles']].describe()\n",
    "\n",
    "\n",
    "### 27  cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume: To save output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for 60 miles, 6-20 sites\n",
    "\n",
    "output_clustered = '../data_files/output/clustered_locations_60_miles_site_count_6_20.xlsx'\n",
    "output_analysis = '../data_files/output/cluster_analysis_60_miles_site_count_6_20.xlsx'\n",
    "\n",
    "df_adjusted_3.to_excel(output_clustered, index=False)\n",
    "cluster_adj_analysis_3.to_excel(output_analysis, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for 300 miles, 6-10 sites\n",
    "\n",
    "output_clustered = '../data_files/output/clustered_locations_300_miles_site_count_6_10.xlsx'\n",
    "output_analysis = '../data_files/output/cluster_analysis_300_miles_site_count_6_10.xlsx'\n",
    "\n",
    "df_adjusted_5.to_excel(output_clustered, index=False)\n",
    "cluster_adj_analysis_5.to_excel(output_analysis, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
