{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New idea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) total headcount across all sclusters\n",
    "2) parameter -> #regions\n",
    "3) calculate average headcount per region\n",
    "4) calculate min & max headcount per region based on threshold parameter values (eg 20% width, ie. 80%-120% of average headcount is acceptable)\n",
    "5) assign clusters to region iteratively based on max distance b/w clsuter centers (within acceptance criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib import pyplot as plt\n",
    "import geopandas\n",
    "from geodatasets import get_path\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_miles(coord1, coord2):\n",
    "    \"\"\"Calculate distance between two coordinates in miles\"\"\"\n",
    "    return geodesic(coord1, coord2).miles\n",
    "\n",
    "\n",
    "def safe_join(series):\n",
    "    \"\"\"Join series values handling different data types and null values\"\"\"\n",
    "    if series is None or len(series) == 0:\n",
    "        return \"\"\n",
    "    return ', '.join(str(x) for x in pd.Series(series).dropna().unique() if str(x).strip() != '')\n",
    "\n",
    "\n",
    "# Analyze regions an\n",
    "def analyze_regions(df):\n",
    "    \"\"\"Generate summary statistics and staffing analysis for each campus.\"\"\"\n",
    "    cluster_stats = []\n",
    "    cluster_ids = df['cluster_id'].unique()\n",
    "    \n",
    "    # Compute quartile thresholds for OPS_H from valid (non-outlier) clusters.\n",
    "    campus_sizes = []\n",
    "    for cid in cluster_ids:\n",
    "        cluster_data = df[df['cluster_id'] == cid]\n",
    "        #if not cluster_data['is_outlier'].all():\n",
    "        #    campus_sizes.append(cluster_data['OPS_H'].sum())\n",
    "    if campus_sizes:\n",
    "        q1_size = np.percentile(campus_sizes, 25)\n",
    "        q2_size = np.percentile(campus_sizes, 50)\n",
    "        q3_size = np.percentile(campus_sizes, 75)\n",
    "    else:\n",
    "        q1_size, q2_size, q3_size = 15000, 30000, 50000\n",
    "\n",
    "    for cid in cluster_ids:\n",
    "        cluster_data = df[df['cluster_id'] == cid]\n",
    "        center_lat = cluster_data['latitude'].mean()\n",
    "        center_lon = cluster_data['longitude'].mean()\n",
    "        \n",
    "        max_distance = 0\n",
    "        sites = cluster_data[['latitude', 'longitude']].values\n",
    "        if len(sites) > 1:\n",
    "            for i in range(len(sites)):\n",
    "                for j in range(i+1, len(sites)):\n",
    "                    d = calculate_distance_miles(sites[i], sites[j])\n",
    "                    if d > max_distance:\n",
    "                        max_distance = d\n",
    "        \n",
    "        cluster_aa_hc = cluster_data['OPS_H'].sum()\n",
    "        #cluster_ops_hc = cluster_data['OPS_S'].sum()\n",
    "        \n",
    "        stats = {\n",
    "            'cluster_id': cid,\n",
    "            'num_sites': len(cluster_data),\n",
    "            'size_category': size_category,\n",
    "            'Cluster_AA_HC': cluster_aa_hc,\n",
    "            'Cluster_OPS_HC': cluster_ops_hc,\n",
    "            \n",
    "            'center_latitude': center_lat,\n",
    "            'center_longitude': center_lon,\n",
    "            'max_distance_miles': round(max_distance, 2),\n",
    "            \n",
    "        }\n",
    "        cluster_stats.append(stats)\n",
    "    \n",
    "    df_stats = pd.DataFrame(cluster_stats)\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "\n",
    "num_regions = 8\n",
    "threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load cluster files\n",
    "\n",
    "output_clustered = '../data_files/output/after_outlier/clustered_locations_300_miles_site_count_6_10_outlier_2.xlsx'\n",
    "output_analysis = '../data_files/output/after_outlier/cluster_analysis_300_miles_site_count_6_10_outlier_2.xlsx'\n",
    "\n",
    "df_clustered = pd.read_excel(output_clustered)\n",
    "cluster_analysis = pd.read_excel(output_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>center_latitude</th>\n",
       "      <th>center_longitude</th>\n",
       "      <th>num_sites_outlier_1</th>\n",
       "      <th>Cluster_AA_HC_outlier_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.210377</td>\n",
       "      <td>-110.970245</td>\n",
       "      <td>18</td>\n",
       "      <td>9642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>28.418910</td>\n",
       "      <td>-81.217432</td>\n",
       "      <td>9</td>\n",
       "      <td>6879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>29.886499</td>\n",
       "      <td>-95.632105</td>\n",
       "      <td>7</td>\n",
       "      <td>3882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>32.595851</td>\n",
       "      <td>-116.949160</td>\n",
       "      <td>6</td>\n",
       "      <td>5502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30.287884</td>\n",
       "      <td>-81.785339</td>\n",
       "      <td>10</td>\n",
       "      <td>9285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id  center_latitude  center_longitude  num_sites_outlier_1  \\\n",
       "0           0        32.210377       -110.970245                   18   \n",
       "1         200        28.418910        -81.217432                    9   \n",
       "2         136        29.886499        -95.632105                    7   \n",
       "3          46        32.595851       -116.949160                    6   \n",
       "4           4        30.287884        -81.785339                   10   \n",
       "\n",
       "   Cluster_AA_HC_outlier_1  \n",
       "0                     9642  \n",
       "1                     6879  \n",
       "2                     3882  \n",
       "3                     5502  \n",
       "4                     9285  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### use cluster analysis file directly\n",
    "### note this is orginal cluster center (before outliers added)\n",
    "rel_cols = ['cluster_id','center_latitude','center_longitude','num_sites_outlier_1','Cluster_AA_HC_outlier_1']\n",
    "\n",
    "rel_cluster_data =  cluster_analysis[rel_cols]\n",
    "rel_cluster_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806840 100855.0 80684.0 121026.0\n"
     ]
    }
   ],
   "source": [
    "### acceptance conditions\n",
    "\n",
    "total_AA_HC = rel_cluster_data['Cluster_AA_HC_outlier_1'].sum()\n",
    "avg_AA_HC_region = total_AA_HC/num_regions\n",
    "\n",
    "min_AA_HC_region = (1 - threshold) * avg_AA_HC_region\n",
    "max_AA_HC_region = (1 + threshold) * avg_AA_HC_region\n",
    "\n",
    "print(total_AA_HC, avg_AA_HC_region, min_AA_HC_region, max_AA_HC_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_sites_outlier_1</th>\n",
       "      <th>Cluster_AA_HC_outlier_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>111.000000</td>\n",
       "      <td>111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.072072</td>\n",
       "      <td>7268.828829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.141255</td>\n",
       "      <td>3784.693337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>4291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>6889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>9698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>18288.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_sites_outlier_1  Cluster_AA_HC_outlier_1\n",
       "count           111.000000               111.000000\n",
       "mean             10.072072              7268.828829\n",
       "std               3.141255              3784.693337\n",
       "min               6.000000              1730.000000\n",
       "25%               8.000000              4291.000000\n",
       "50%               9.000000              6889.000000\n",
       "75%              11.000000              9698.000000\n",
       "max              22.000000             18288.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##how many clusters have headcount < min_AA_HC_region \n",
    "print(len(rel_cluster_data[rel_cluster_data['Cluster_AA_HC_outlier_1'] < min_AA_HC_region]))\n",
    "print(len(rel_cluster_data[rel_cluster_data['Cluster_AA_HC_outlier_1'] < min_AA_HC_region])/ len(rel_cluster_data))\n",
    "\n",
    "rel_cluster_data[['num_sites_outlier_1','Cluster_AA_HC_outlier_1']].describe()\n",
    "\n",
    "## 100% not met requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "df_adjusted = rel_cluster_data.copy()\n",
    "#df_adjusted.loc[:,'merged'] = np.nan\n",
    "\n",
    "print(df_adjusted['cluster_id'].nunique())\n",
    "\n",
    "# Merge clusters inot regions based on headcount\n",
    "\n",
    "clusters = df_adjusted['cluster_id'].unique()\n",
    "cluster_centers = {cid: (df_adjusted[df_adjusted['cluster_id'] == cid]['center_latitude'].mean(),\n",
    "                         df_adjusted[df_adjusted['cluster_id'] == cid]['center_longitude'].mean())\n",
    "                    for cid in clusters}\n",
    "for cid in clusters:\n",
    "    cluster_data = df_adjusted[df_adjusted['cluster_id'] == cid]\n",
    "\n",
    "    ##if already merged then skip\n",
    "    #print(cluster_data['merged'].to_numpy()[0])\n",
    "    #if ~cluster_data['merged'].isna().any():\n",
    "    #    continue\n",
    "\n",
    "    aa_hc = cluster_data['Cluster_AA_HC_outlier_1'].sum()\n",
    "    if aa_hc < min_AA_HC_region:\n",
    "    #if len(cluster_data) < min_sites:\n",
    "        candidate = None\n",
    "        min_dist = float('inf')\n",
    "        for other_cid in clusters:\n",
    "            if other_cid == cid:\n",
    "                continue\n",
    "            other_data = df_adjusted[df_adjusted['cluster_id'] == other_cid]\n",
    "            #combined_sites = len(cluster_data) + len(other_data)\n",
    "            combined_aa_hc = aa_hc + other_data['Cluster_AA_HC_outlier_1'].sum()\n",
    "            if combined_aa_hc <= max_AA_HC_region:\n",
    "                d = calculate_distance_miles(cluster_centers[cid], cluster_centers[other_cid])\n",
    "                if d < min_dist:\n",
    "                    min_dist = d\n",
    "                    candidate = other_cid\n",
    "        #print(candidate)\n",
    "        if candidate is not None:\n",
    "            df_adjusted.loc[df_adjusted['cluster_id'] == cid, 'cluster_id'] = candidate\n",
    "            \n",
    "            \n",
    "\n",
    "            ## retain initial cluster id \n",
    "            #df_adjusted.loc[df_adjusted['cluster_id'] == cid, 'initial_cluster_id'] = cid\n",
    "            \n",
    "            ##cluster id based on candidate\n",
    "            #df_adjusted.loc[df_adjusted['cluster_id'] == cid, 'cluster_id'] = candidate\n",
    "            \n",
    "\n",
    "\n",
    "print(df_adjusted['cluster_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping to retain old cluster id\n",
    "\n",
    "org_clusters = rel_cluster_data[['cluster_id']]\n",
    "org_clusters = org_clusters.rename(columns={'cluster_id':'initial_cluster_id'})\n",
    "\n",
    "# Concatenate without ignoring index\n",
    "df_adjusted_2 = pd.concat([df_adjusted, org_clusters], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'is_outlier'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workplace/Campus-Staffing-ws/src/Campus-Staffing/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'is_outlier'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## groupby cluster_id \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m cluster_adj_analysis = \u001b[43manalyze_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_adjusted_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[114]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36manalyze_clusters\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cid \u001b[38;5;129;01min\u001b[39;00m cluster_ids:\n\u001b[32m     96\u001b[39m     cluster_data = df[df[\u001b[33m'\u001b[39m\u001b[33mcluster_id\u001b[39m\u001b[33m'\u001b[39m] == cid]\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcluster_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mis_outlier\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.all():\n\u001b[32m     98\u001b[39m         campus_sizes.append(cluster_data[\u001b[33m'\u001b[39m\u001b[33mOPS_H\u001b[39m\u001b[33m'\u001b[39m].sum())\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m campus_sizes:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workplace/Campus-Staffing-ws/src/Campus-Staffing/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workplace/Campus-Staffing-ws/src/Campus-Staffing/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'is_outlier'"
     ]
    }
   ],
   "source": [
    "## groupby cluster_id \n",
    "\n",
    "cluster_adj_analysis = analyze_clusters(df_adjusted_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "#### trying a single pass to debug\n",
    "\n",
    "\n",
    "df_adjusted = rel_cluster_data.copy()\n",
    "clusters = df_adjusted['cluster_id'].unique()\n",
    "cluster_centers = {cid: (df_adjusted[df_adjusted['cluster_id'] == cid]['center_latitude'].to_numpy()[0],\n",
    "                         df_adjusted[df_adjusted['cluster_id'] == cid]['center_longitude'].to_numpy()[0])\n",
    "                    for cid in clusters}\n",
    "\n",
    "\n",
    "cid = clusters[0]\n",
    "print(cid)\n",
    "\n",
    "cluster_data = df_adjusted[df_adjusted['cluster_id'] == cid]\n",
    "aa_hc = cluster_data['Cluster_AA_HC_outlier_1'].sum()\n",
    "#print(aa_hc)\n",
    "#print(min_AA_HC_region)\n",
    "\n",
    "if aa_hc < min_AA_HC_region:\n",
    "    candidate = None\n",
    "    min_dist = float('inf')\n",
    "    for other_cid in clusters:\n",
    "        if other_cid == cid:\n",
    "            continue\n",
    "        #print(other_cid)\n",
    "        other_data = df_adjusted[df_adjusted['cluster_id'] == other_cid]\n",
    "        combined_aa_hc = aa_hc + other_data['Cluster_AA_HC_outlier_1'].sum()\n",
    "        #print(combined_aa_hc)\n",
    "\n",
    "        if combined_aa_hc <= max_AA_HC_region:\n",
    "            #print(cluster_centers[cid])\n",
    "            #print(cluster_centers[other_cid])\n",
    "            d = calculate_distance_miles(cluster_centers[cid], cluster_centers[other_cid])\n",
    "            if d < min_dist:\n",
    "                min_dist = d\n",
    "                candidate = other_cid\n",
    "    \n",
    "    print(candidate)\n",
    "    if candidate is not None:\n",
    "        \n",
    "        ##create merged cluster id based on candidate\n",
    "        df_adjusted.loc[df_adjusted['cluster_id'] == cid, 'merged_cluster_id'] = candidate\n",
    "        df_adjusted.loc[df_adjusted['cluster_id'] == cid, 'merged'] = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>center_latitude</th>\n",
       "      <th>center_longitude</th>\n",
       "      <th>num_sites_outlier_1</th>\n",
       "      <th>Cluster_AA_HC_outlier_1</th>\n",
       "      <th>merged</th>\n",
       "      <th>initial_cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cluster_id, center_latitude, center_longitude, num_sites_outlier_1, Cluster_AA_HC_outlier_1, merged, initial_cluster_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted[df_adjusted['initial_cluster_id']==]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>center_latitude</th>\n",
       "      <th>center_longitude</th>\n",
       "      <th>num_sites_outlier_1</th>\n",
       "      <th>Cluster_AA_HC_outlier_1</th>\n",
       "      <th>merged</th>\n",
       "      <th>initial_cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cluster_id, center_latitude, center_longitude, num_sites_outlier_1, Cluster_AA_HC_outlier_1, merged, initial_cluster_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adjusted[df_adjusted['cluster_id']==105]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
