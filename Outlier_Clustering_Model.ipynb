{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier module that can be added to any clustering scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_locations(file_path):\n",
    "    \"\"\"Load location data from Excel file\"\"\"\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def calculate_distance_miles(coord1, coord2):\n",
    "    \"\"\"Calculate distance between two coordinates in miles\"\"\"\n",
    "    return geodesic(coord1, coord2).miles\n",
    "\n",
    "def safe_join(series):\n",
    "    \"\"\"Join series values handling different data types and null values\"\"\"\n",
    "    if series is None or len(series) == 0:\n",
    "        return \"\"\n",
    "    return ', '.join(str(x) for x in pd.Series(series).dropna().unique() if str(x).strip() != '')\n",
    "\n",
    "\n",
    "# Campus Size Category based on quartiles of OPS_H sum\n",
    "def get_size_category(ops_h_sum, q1, q2, q3):\n",
    "    \"\"\"Classify campus size based on OPS_H sum quartiles\"\"\"\n",
    "    if ops_h_sum < q1:\n",
    "        return \"Small\"\n",
    "    elif ops_h_sum < q2:\n",
    "        return \"Medium\"\n",
    "    elif ops_h_sum < q3:\n",
    "        return \"Large\"\n",
    "    else:\n",
    "        return \"X-Large\"\n",
    "\n",
    "\n",
    "# HR Staffing Levels (base rules)\n",
    "def get_hr_staffing_levels(size_category):\n",
    "    \"\"\"\n",
    "    Returns recommended HR staffing levels based on size category.\n",
    "    Base staffing:\n",
    "      X-Large: Campus Leader=1, HR_L4=16, HR_L5=6, HR_L6=5, HR_L7=2\n",
    "      Large:   Campus Leader=1, HR_L4=11, HR_L5=5, HR_L6=3, HR_L7=1\n",
    "      Medium:  Campus Leader=1, HR_L4=8,  HR_L5=4, HR_L6=2, HR_L7=0\n",
    "      Small:   Campus Leader=1, HR_L4=5,  HR_L5=3, HR_L6=2, HR_L7=0\n",
    "      Multi-Site: Campus Leader=1, HR_L4=1, HR_L5=1, HR_L6=0, HR_L7=0\n",
    "    \"\"\"\n",
    "    staffing_matrix = {\n",
    "        'Small': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 5,\n",
    "            'HR_L5': 3,\n",
    "            'HR_L6': 2,\n",
    "            'HR_L7': 0\n",
    "        },\n",
    "        'Medium': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 8,\n",
    "            'HR_L5': 4,\n",
    "            'HR_L6': 2,\n",
    "            'HR_L7': 0\n",
    "        },\n",
    "        'Large': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 11,\n",
    "            'HR_L5': 5,\n",
    "            'HR_L6': 3,\n",
    "            'HR_L7': 1\n",
    "        },\n",
    "        'X-Large': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 16,\n",
    "            'HR_L5': 6,\n",
    "            'HR_L6': 5,\n",
    "            'HR_L7': 2\n",
    "        },\n",
    "        'Multi-Site': {\n",
    "            'Campus_Leader': 1,\n",
    "            'HR_L4': 1,\n",
    "            'HR_L5': 1,\n",
    "            'HR_L6': 0,\n",
    "            'HR_L7': 0\n",
    "        }\n",
    "    }\n",
    "    return staffing_matrix.get(size_category, {\n",
    "        'Campus_Leader': 0,\n",
    "        'HR_L4': 0,\n",
    "        'HR_L5': 0,\n",
    "        'HR_L6': 0,\n",
    "        'HR_L7': 0\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Analyze clusters and perform HR/staffing analysis.\n",
    "def analyze_clusters(df):\n",
    "    \"\"\"Generate summary statistics and staffing analysis for each campus.\"\"\"\n",
    "    cluster_stats = []\n",
    "    cluster_ids = df['cluster_id'].unique()\n",
    "    \n",
    "    # Compute quartile thresholds for OPS_H from valid (non-outlier) clusters.\n",
    "    campus_sizes = []\n",
    "    for cid in cluster_ids:\n",
    "        cluster_data = df[df['cluster_id'] == cid]\n",
    "        if not cluster_data['is_outlier'].all():\n",
    "            campus_sizes.append(cluster_data['OPS_H'].sum())\n",
    "    if campus_sizes:\n",
    "        q1_size = np.percentile(campus_sizes, 25)\n",
    "        q2_size = np.percentile(campus_sizes, 50)\n",
    "        q3_size = np.percentile(campus_sizes, 75)\n",
    "    else:\n",
    "        q1_size, q2_size, q3_size = 15000, 30000, 50000\n",
    "\n",
    "    for cid in cluster_ids:\n",
    "        cluster_data = df[df['cluster_id'] == cid]\n",
    "        center_lat = cluster_data['latitude'].mean()\n",
    "        center_lon = cluster_data['longitude'].mean()\n",
    "        \n",
    "        max_distance = 0\n",
    "        sites = cluster_data[['latitude', 'longitude']].values\n",
    "        if len(sites) > 1:\n",
    "            for i in range(len(sites)):\n",
    "                for j in range(i+1, len(sites)):\n",
    "                    d = calculate_distance_miles(sites[i], sites[j])\n",
    "                    if d > max_distance:\n",
    "                        max_distance = d\n",
    "        \n",
    "        cluster_aa_hc = cluster_data['OPS_H'].sum()\n",
    "        cluster_ops_hc = cluster_data['OPS_S'].sum()\n",
    "        \n",
    "        # Current staffing summary (if such columns exist)\n",
    "        current_staffing = {\n",
    "            'Current_Campus_Leader': 1 if 'Campus_Leader' in cluster_data.columns else 0,\n",
    "            'Current_HR_L4': cluster_data['HR_4'].sum() if 'HR_4' in cluster_data.columns else 0,\n",
    "            'Current_HR_L5': cluster_data['HR_5'].sum() if 'HR_5' in cluster_data.columns else 0,\n",
    "            'Current_HR_L6': cluster_data['HR_6'].sum() if 'HR_6' in cluster_data.columns else 0,\n",
    "            'Current_HR_L7': cluster_data['HR_7'].sum() if 'HR_7' in cluster_data.columns else 0\n",
    "        }\n",
    "        current_hr_total = sum(current_staffing.values())\n",
    "        current_gearing_ratio = (cluster_aa_hc / current_hr_total) if current_hr_total else None\n",
    "        current_gearing_ratio_ops = (cluster_ops_hc / current_hr_total) if current_hr_total else None\n",
    "        \n",
    "        if cluster_data['multi_site'].any():\n",
    "            size_category = \"Multi-Site\"\n",
    "            new_hr_staffing = get_hr_staffing_levels(\"Multi-Site\")\n",
    "        else:\n",
    "            size_category = get_size_category(cluster_aa_hc, q1_size, q2_size, q3_size)\n",
    "            new_hr_staffing = get_hr_staffing_levels(size_category)\n",
    "        \n",
    "        new_hr_total = sum(new_hr_staffing.values())\n",
    "        new_gearing_ratio = (cluster_aa_hc / new_hr_total) if new_hr_total else None\n",
    "        new_gearing_ratio_ops = (cluster_ops_hc / new_hr_total) if new_hr_total else None\n",
    "        \n",
    "        stats = {\n",
    "            'cluster_id': cid,\n",
    "            'num_sites': len(cluster_data),\n",
    "            'size_category': size_category,\n",
    "            'Cluster_AA_HC': cluster_aa_hc,\n",
    "            'Cluster_OPS_HC': cluster_ops_hc,\n",
    "            'Current_Campus_Leader': current_staffing['Current_Campus_Leader'],\n",
    "            'Current_HR_L4': current_staffing['Current_HR_L4'],\n",
    "            'Current_HR_L5': current_staffing['Current_HR_L5'],\n",
    "            'Current_HR_L6': current_staffing['Current_HR_L6'],\n",
    "            'Current_HR_L7': current_staffing['Current_HR_L7'],\n",
    "            'Current_HR_Total': current_hr_total,\n",
    "            'Current_Gearing_Ratio_AA': current_gearing_ratio,\n",
    "            'Current_Gearing_Ratio_OPS': current_gearing_ratio_ops,\n",
    "            'New_Campus_Leader': new_hr_staffing['Campus_Leader'],\n",
    "            'New_HR_L4': new_hr_staffing['HR_L4'],\n",
    "            'New_HR_L5': new_hr_staffing['HR_L5'],\n",
    "            'New_HR_L6': new_hr_staffing['HR_L6'],\n",
    "            'New_HR_L7': new_hr_staffing['HR_L7'],\n",
    "            'New_HR_Total': new_hr_total,\n",
    "            'New_Gearing_Ratio_AA': new_gearing_ratio,\n",
    "            'New_Gearing_Ratio_OPS': new_gearing_ratio_ops,\n",
    "            'country': safe_join(cluster_data['country']),\n",
    "            'markets': safe_join(cluster_data['market']),\n",
    "            'cities': safe_join(cluster_data['city']),\n",
    "            'states': safe_join(cluster_data['state']),\n",
    "            'center_latitude': center_lat,\n",
    "            'center_longitude': center_lon,\n",
    "            'max_distance_miles': round(max_distance, 2),\n",
    "            'num_reassigned_outliers': len(cluster_data[cluster_data['reassignment_type'].notnull()])\n",
    "        }\n",
    "        cluster_stats.append(stats)\n",
    "    \n",
    "    df_stats = pd.DataFrame(cluster_stats)\n",
    "    # Round gearing ratios for presentation.\n",
    "    for col in ['Current_Gearing_Ratio_AA', 'Current_Gearing_Ratio_OPS',\n",
    "                'New_Gearing_Ratio_AA', 'New_Gearing_Ratio_OPS']:\n",
    "        df_stats[col] = df_stats[col].apply(lambda x: round(x, 2) if pd.notnull(x) else x)\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Logic 1: Mapping individual outliers to closest campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load cluster files\n",
    "\n",
    "output_clustered = '../data_files/output/clustered_locations_300_miles_site_count_6_10.xlsx'\n",
    "output_analysis = '../data_files/output/cluster_analysis_300_miles_site_count_6_10.xlsx'\n",
    "\n",
    "df_clustered = pd.read_excel(output_clustered)\n",
    "cluster_analysis = pd.read_excel(output_analysis)\n",
    "\n",
    "df_clustered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign outlier based on min distance\n",
    "def find_closest_cluster(outlier, df_clustered):\n",
    "    outlier_coords = (outlier['latitude'], outlier['longitude'])\n",
    "    valid_clusters = df_clustered[(~df_clustered['is_outlier']) & (df_clustered['country'] == outlier['country'])]\n",
    "    closest = None\n",
    "    min_distance = float('inf')\n",
    "    for cid in valid_clusters['cluster_id'].unique():\n",
    "        cluster_data = df_clustered[df_clustered['cluster_id'] == cid]\n",
    "        center = (cluster_data['latitude'].mean(), cluster_data['longitude'].mean())\n",
    "        distance = calculate_distance_miles(outlier_coords, center)\n",
    "        #if distance <= commute_radius and distance < min_distance:\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest = {'cluster_id': cid, 'distance': distance, 'match_type': 'assigned by min distance'}\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = df_clustered.copy()\n",
    "\n",
    "# First pass: reassign individual outliers based on min distance to exsiting clusters\n",
    "outliers = df_adjusted[df_adjusted['is_outlier']].copy()\n",
    "print(f\"\\nProcessing {len(outliers)} outliers for reassignment...\")\n",
    "for idx, outlier in outliers.iterrows():\n",
    "    match_result = find_closest_cluster(outlier, df_adjusted)\n",
    "    #print(match_result)\n",
    "    #if match_result:\n",
    "    cid = match_result['cluster_id']\n",
    "    #current_size = len(df_clustered[df_clustered['cluster_id'] == cid])\n",
    "    #if current_size < max_sites:\n",
    "    df_adjusted.at[idx, 'cluster_id'] = cid\n",
    "    df_adjusted.at[idx, 'is_outlier'] = False\n",
    "    df_adjusted.at[idx, 'outlier_reassigned'] = True\n",
    "    df_adjusted.at[idx, 'reassignment_type'] = match_result['match_type']\n",
    "    df_adjusted.at[idx, 'distance_from_campus'] = round(match_result['distance'],1)\n",
    "    #print(f\"Reassigned outlier {idx} to cluster {cid} (distance: {match_result['distance']:.2f} miles)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analyse adjusted clusters new constraint\n",
    "cluster_adj_analysis = analyze_clusters(df_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merging certain columns of new cluster analysis with previous\n",
    "\n",
    "## except outliers, summary of remaining clusters\n",
    "cluster_analysis_no_outlier = cluster_analysis[~(cluster_analysis['cluster_id'] == -1)].drop(columns=['num_reassigned_outliers'])\n",
    "\n",
    "\n",
    "## relevant columns from new cluster analyis\n",
    "to_merge = cluster_adj_analysis[['cluster_id','num_sites','Cluster_AA_HC','Cluster_OPS_HC','max_distance_miles','num_reassigned_outliers']]\n",
    "\n",
    "to_merge = to_merge.rename(columns={c: c+'_outlier_1' for c in to_merge.columns if c not in ['cluster_id','num_reassigned_outliers']})\n",
    "\n",
    "\n",
    "### merge on cluster_id\n",
    "\n",
    "cluster_analysis_merged = cluster_analysis_no_outlier.merge(to_merge, on='cluster_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### intermediate save\n",
    "\n",
    "#### for 60 miles, 6-20 sites with outliers\n",
    "\n",
    "output_clustered = '../data_files/output/after_outlier/clustered_locations_60_miles_site_count_6_20_outlier_1.xlsx'\n",
    "output_analysis = '../data_files/output/after_outlier/cluster_analysis_60_miles_site_count_6_20_outlier_1.xlsx'\n",
    "\n",
    "df_adjusted.to_excel(output_clustered, index=False)\n",
    "cluster_analysis_merged.to_excel(output_analysis, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Logic 2: Grouping outliers within a campus into nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_node_min = 2\n",
    "outlier_node_max = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted_2 = df_adjusted.copy()\n",
    "\n",
    "# Second pass: group outliers into multi-site nodes (nested under main cluster)\n",
    "\n",
    "outliers = df_adjusted_2[df_adjusted_2['initial_outlier']]\n",
    "new_node_id = 1\n",
    "##only processing outliers\n",
    "for cid in outliers['cluster_id'].unique():\n",
    "    \n",
    "    #one main cluster at a time\n",
    "    outlier_data = outliers[outliers['cluster_id'] == cid]\n",
    "    \n",
    "    if len(outlier_data) > outlier_node_max:\n",
    "        ## split using constrained kmeans clustering\n",
    "        changed = True\n",
    "        n_subclusters = int(np.ceil(len(outlier_data) / outlier_node_max))\n",
    "        coords = outlier_data[['latitude', 'longitude']].values\n",
    "        constr_kmeans = KMeansConstrained(n_clusters=n_subclusters, size_min=outlier_node_min, size_max=outlier_node_max, random_state=42)\n",
    "        sub_labels = constr_kmeans.fit_predict(coords)\n",
    "        for sub in np.unique(sub_labels):\n",
    "            indices = outlier_data.index[sub_labels == sub]\n",
    "            df_adjusted_2.loc[indices, 'outlier_node_id'] = new_node_id\n",
    "            df_adjusted_2.loc[indices, 'multi_site'] = True\n",
    "            df_adjusted_2.loc[indices, 'reassignment_type_2'] = \"adjusted multi-site node\"\n",
    "            new_node_id += 1\n",
    "\n",
    "    elif len(outlier_data) <= outlier_node_max and len(outlier_data) >= outlier_node_min:\n",
    "        ## no need to perform additional clustering, just group them into a node\n",
    "        changed = True\n",
    "        indices = outlier_data.index\n",
    "        df_adjusted_2.loc[indices, 'outlier_node_id'] = new_node_id\n",
    "        df_adjusted_2.loc[indices, 'multi_site'] = True\n",
    "        df_adjusted_2.loc[indices, 'reassignment_type_2'] = \"auto compliant multi-site node\"\n",
    "        new_node_id += 1\n",
    "\n",
    "    else:\n",
    "        ## no grouping, but add node id and update reassignment type\n",
    "        changed = False\n",
    "        indices = outlier_data.index\n",
    "        df_adjusted_2.loc[indices, 'outlier_node_id'] = new_node_id\n",
    "        df_adjusted_2.loc[indices, 'multi_site'] = False\n",
    "        df_adjusted_2.loc[indices, 'reassignment_type_2'] = \"stay single outlier\"\n",
    "        new_node_id += 1\n",
    "\n",
    "print(df_adjusted_2['cluster_id'].nunique())\n",
    "print(len(outliers))\n",
    "print(df_adjusted_2['outlier_node_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add outlier node summaries to cluster summary\n",
    "\n",
    "to_check = df_adjusted_2.groupby(['cluster_id','outlier_node_id','reassignment_type_2']).size().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodal_summary = df_adjusted_2.groupby(['cluster_id'])['outlier_node_id'].nunique().to_frame('num_outlier_nodes').reset_index()\n",
    "\n",
    "### merge on cluster_id\n",
    "cluster_analysis_merged = cluster_analysis_merged.merge(nodal_summary, on='cluster_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final save\n",
    "\n",
    "#### for 300 miles, 6-10 sites with outliers\n",
    "\n",
    "output_clustered = '../data_files/output/after_outlier/clustered_locations_300_miles_site_count_6_10_outlier_2.xlsx'\n",
    "output_analysis = '../data_files/output/after_outlier/cluster_analysis_300_miles_site_count_6_10_outlier_2.xlsx'\n",
    "\n",
    "df_adjusted_2.to_excel(output_clustered, index=False)\n",
    "cluster_analysis_merged.to_excel(output_analysis, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
